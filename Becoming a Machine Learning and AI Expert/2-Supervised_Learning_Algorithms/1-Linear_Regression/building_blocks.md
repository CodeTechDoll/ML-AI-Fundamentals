# Building Blocks

Here is a list of small tasks that build up an understanding of the concepts presented in the linear regression lesson:

1. **Visualize data**: Create a scatter plot of the input features and target variable to visually inspect the linear relationship between them. You can use a sample dataset or real-world data.
2. **Check assumptions**: Test the linear regression assumptions (linearity, independence, homoscedasticity, normality) using appropriate statistical tests and visualizations.
3. **Train a model**: Train a linear regression model using a sample dataset or real-world data. You can use scikit-learn, TensorFlow, or any other library of your choice.
4. **Experiment with optimization techniques**: Compare the performance of different optimization techniques, such as gradient descent and normal equations, for training the linear regression model.
5. **Evaluate the model**: Calculate evaluation metrics (MAE, MSE, RMSE, R-squared) for the trained linear regression model and interpret the results.
6. **Plot residuals**: Create a residual plot to visualize the distribution of errors and analyze the model's performance.
7. **Regularization**: Implement L1 (Lasso) and L2 (Ridge) regularization techniques to control the complexity of the linear regression model and prevent overfitting.
8. **Feature scaling**: Experiment with feature scaling methods, such as standardization and normalization, to see how they affect the performance of the linear regression model.
9. **Feature selection**: Try different combinations of input features to identify the most important features for predicting the target variable.
10. **Cross-validation**: Use cross-validation techniques to assess the generalization performance of the linear regression model.

By completing these tasks, you will build a solid understanding of linear regression, its assumptions, training and evaluation techniques, and how to apply it to real-world problems.
